{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Symposium \"Recent Advances in Deep Learning Systems\", Reisensburg/UUlm, 05.11.2019 - 07.11.2019\n",
    "##### Christian Jarvers, Heinke Hihn, Institute for Neural Information Processing, UUlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Progression of Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we build up discriminative deep learning step by step and train increasingly complex classifiers on several datasets.\n",
    "\n",
    "We will use some of the standard example datasets of the machine learning community:\n",
    "\n",
    "- MNIST: a dataset of handwritten digits, which consists of 60000 grayscale images of size 28x28\n",
    "- fashionMNIST: a dataset of the same format as MNIST, but with pictures of clothing items instead\n",
    "- CIFAR10: a dataset of 50000 colour images of ten different object categories, size 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_imgs, mnist_lbls), (mnist_test_imgs, mnist_test_lbls) = tf.keras.datasets.mnist.load_data()\n",
    "mnist_imgs = mnist_imgs.reshape(-1, 28, 28, 1) / 255.0\n",
    "mnist_test_imgs = mnist_test_imgs.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "(fashion_imgs, fashion_lbls), (fashion_val_imgs, fashion_val_lbls) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "fashion_imgs = fashion_imgs.reshape(-1, 28, 28, 1) / 255.0\n",
    "fashion_val_imgs = fashion_val_imgs.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "(cifar_imgs, cifar_lbls), (mnist_test_imgs, mnist_test_lbls) = tf.keras.datasets.mnist.load_data()\n",
    "mnist_imgs = mnist_imgs.reshape(-1, 28, 28, 1) / 255.0\n",
    "mnist_test_imgs = mnist_test_imgs.reshape(-1, 28, 28, 1) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **linear classifier** processes an input vector $x$ by multiplying it with a weight matrix $w$ and adding a bias vector $b$.\n",
    "\n",
    "$$ y = w \\cdot x + b $$\n",
    "\n",
    "For example, for an MNIST image of size (28x28), $x$ is a 784-dimensional vector. The output vector $y$ should have as many dimensions as there are classes, for example 10 in the case of MNIST.\n",
    "\n",
    "For classification problems, we typically want to assign a probability to each class, which should correspond to the confidence of our classifier that an object of that class is in the image. Thus, if we know that there is only one object per image, we want all outputs to sum to 1. We can ensure this by transforming $y$ with the softmax function to get our predictions $p$.\n",
    "\n",
    "$$p = softmax(y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement and train a linear classifier for each of the example datasets, for example using `tf.keras.layers.Dense`. A linear classifier is often a good baseline model. It will perform badly on complicated tasks, so your model should always outperform this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much room for experimentation with a linear classifier, but try out different loss functions and different [optimization algorithms](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) (e.g., [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) or [stochastic gradient descent](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD)). Many of these optimizers have hyperparameters like the learning rate, which you can experiment with as well. Record your best resutls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **multi-layer perceptron** (MLP), often just referred to as an **artificial neural network** (ANN) is a sequence of layers. Each layer is similar to a linear classifier, with one crucial difference:\n",
    "\n",
    "$$y = f(w * x + b)$$\n",
    "\n",
    "The output of the linear transformation is passed through a non-linearity $f()$. This drastically increases the learning capabilities of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multilayer perceptron has many more degrees of freedom in the architecture design. You can vary the number of layers, the number of neurons per layer, as well as the non-linear activation function used. A common design pattern is to start with large hidden layers lower in the network and decrease the size in higher layers, yielding a kind of pyramid structure. [Sigmoid](https://www.tensorflow.org/api_docs/python/tf/math/sigmoid), [tanh](https://www.tensorflow.org/api_docs/python/tf/math/tanh) used to be common choices for activation functions, but have recently been almost abandoned in favour of the [relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu) and its variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, experiment with different architectures and settings. Now it may become important to monitor the validation accuracy to precent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two approaches above, we have treated images as vectors when feeding them to our classifier. This disregards one crucial fact: images have inherent structure. Pixels that are close to each other are related. In natural images, we can expect neighbouring pixels to have similar values and if they don't this is important information.\n",
    "\n",
    "A multi-layer perceptron can, in theory, discover this fact and learn that neighbouring pixels are related. However, it may have quite a hard time just figuring out this simple fact.\n",
    "\n",
    "In contrast, **convolutional neural networks** have the constraint that nearby pixels belong together. Instead of a weight matrix, they use a **kernel**, a small grid of weights that is applied to each image location. This convolution operation specifically looks for local image features and it does so in each location, yielding invariance against a shift in position.\n",
    "\n",
    "In principle, any network that uses a convolution is a convolutional network. However, there are certain design patterns that are commonly observed. Similar to the weighting operations in an ANN, each convolution is typically followed by a non-linear activation function. Often, a normalization operation like [batch normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) is applied before or after the activation. Since convolutional networks can easily overfit, regularizers like [dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layers are also commonly included. After a few such blocks of convolution, normalization, activation and dropout, a [max-pooling layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) is typically employed. Max pooling reduces the size of the neural representation (known as a **feature map**) by subsampling.\n",
    "\n",
    "After several such convolution blocks, the neural representation is usually converted to a vector using a flattening layer, and then passed through a few dense layers (essentially, an MLP), the last of which is the output, of the same shape as with the previous classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional networks offer a very large design space. It can be helpful to take inspiration from established network architectures like [VGG](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG19) or [inception](https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3). However, the best way to develop an intuition for what works is to try out different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CODE HERE"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
