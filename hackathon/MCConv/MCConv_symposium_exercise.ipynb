{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MCConv_symposium_exercise.ipynb","provenance":[{"file_id":"1TwYRTdEZpvaosBQso3BUdleXhyOl3q8E","timestamp":1567031031170},{"file_id":"1oglHFAG7W_x5N26Y0oK8DQpbYyJWOi0S","timestamp":1566903961443}],"collapsed_sections":["dGHdmTwfoFyK","0t_NBVT0_kON"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dGHdmTwfoFyK","colab_type":"text"},"source":["# Monte Carlo Convolution Exercise"]},{"cell_type":"markdown","metadata":{"id":"AcjpsqV-Yv43","colab_type":"text"},"source":["In this exercise you will implement a simple version of the Monte Carlo Convolution layers, create a network with them, and train it to segment point clouds from the **ShapeNet Part** dataset (https://shapenet.cs.stanford.edu/iccv17/).\n","\n","First load the necessary dependencies by executing the following code:"]},{"cell_type":"code","metadata":{"id":"7uPArEU8gdwU","colab_type":"code","colab":{}},"source":["#Numpy\n","import numpy as np\n","#Library used to load the data\n","import h5py\n","\n","#!pip install -q tensorflow-gpu==2.0.0-beta1\n","try:\n","  %tensorflow_version 2.x  # Colab only.\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0t_NBVT0_kON","colab_type":"text"},"source":["# Data preparation"]},{"cell_type":"markdown","metadata":{"id":"Wzr2LqYw7v5T","colab_type":"text"},"source":["The first thing we will need to do is downloading the data. \n","\n","**ShapeNet** is a dataset of 12k CAD objects from 16 different classes. Each class has several parts that can be segmented, being 50 different parts in total.\n","\n","We have prepared a sampled version of ShapeNet Part in which each object is sampled with 512 points. In order to download these files execute the following commands:"]},{"cell_type":"code","metadata":{"id":"ZvbzHT7RjiUi","colab_type":"code","colab":{}},"source":["!wget https://www.dropbox.com/s/taos2s389ikli6d/shapenet.zip\n","!unzip shapenet.zip"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OLe18cXQmPzn","colab_type":"text"},"source":["If everything went well you should see the hdf5 file in the associated files of the notebook.\n","\n","Here you can see an image with some segmented point clouds from the data set, for different sampling methods.\n","\n","![texto alternativo](https://www.uni-ulm.de/fileadmin/website_uni_ulm/iui.inst.100/institut/Papers/viscom/2018/hermosilla2018mccnn/hermosilla2018-mccnn-segres.jpg)"]},{"cell_type":"markdown","metadata":{"id":"8McDpknj-D1P","colab_type":"text"},"source":["Now, we will prepare the data for training. First we will load the hdf5 binary file and extract the different datasets.\n","\n","For each point in each model we have the 3D position, the class label, the list of neighboring points and the category of object the point belongs to."]},{"cell_type":"code","metadata":{"id":"hZleQfSt_Jf_","colab_type":"code","colab":{}},"source":["dataset = h5py.File(\"shapenet.hdf5\")\n","\n","#Training data.\n","x_train = dataset['train_data'][:] # 3D point coordinates.\n","y_train = dataset['train_labels'][:] # Point label (0-50).\n","pdf_train = dataset['train_pdfs'][:] # PDF value of the point.\n","n_train = dataset['train_neighs'][:] # Indices of the neighboring points.\n","cat_train = dataset['train_cats'][:] # Category of the object.\n","\n","#Validation data.\n","x_val = dataset['val_data'][:] # 3D point coordinates.\n","y_val = dataset['val_labels'][:] # Point label (0-50).\n","pdf_val = dataset['val_pdfs'][:] # PDF value of the point.\n","n_val = dataset['val_neighs'][:] # Indices of the neighboring points.\n","cat_val = dataset['val_cats'][:] # Category of the object.\n","\n","#Test data.\n","x_test = dataset['test_data'][:] # 3D point coordinates.\n","y_test = dataset['test_labels'][:] # Point label (0-50).\n","pdf_test = dataset['test_pdfs'][:] # PDF value of the point.\n","n_test = dataset['test_neighs'][:] # Indices of the neighboring points.\n","cat_test = dataset['test_cats'][:] # Category of the object.\n","\n","print(\"Point cloud training:\", x_train.shape[0])\n","print(\"Point cloud validation:\", x_val.shape[0])\n","print(\"Point cloud testing:\", x_test.shape[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WlN_iUwP_sEi","colab_type":"text"},"source":["# Spatial convolution"]},{"cell_type":"markdown","metadata":{"id":"giBj7Pgp6yJT","colab_type":"text"},"source":["In the next code we will define a Monte Carlo Convolution layer. These layers compute the following equation for all points in the point cloud and for each output feature:\n","\n","$(f\\star k)_o(x)=\\frac{1}{N_i}\\sum_{i}^{N_i}\\sum_{j}^{F_{in}}\\frac{f_{ij}k_{jo}(x_i-x)}{p(x_i)}$\n","\n","where $f_{ij}$ is the input feature $j$ associated with the neighboring point $x_i$, $k_{jo}(x_i-x)$ is the value of the kernel for the feature $j$ and the position $x_i$ with respect to the center point $x$, $p(x_i|x)$ is the probability density function associated with point $x_i$, $N_i$ is the number of neighboring points to $x$, and $F_{in}$ is the number of input features.\n","\n","We will represent each kernel $k_{jo}$ with an MLP. However, with this design we have to create a different kernel for each input feature and output feature. This could not be memory efficient. Instead, we are going to share the first part of the MLP (first hidden layer) among all the kernels in the layer.\n","\n","$MLP_{jo}(x) = \\sum_{w}^{A}H1_{w}(x)W_{wjo}$\n","\n","Here, the $MLP_{jo}$ represents the convolution kernel for the input feature $j$ and output feature $o$. $H1_w$ is the hidden neuron $w$ and $W_{wjo}$ are the weight applied to compute the final output. You can see that, since the first layer is shared, $H1_w$ does not depend on the input or output feature, it is the same for all the kernels. If we plugin this definition in our previous definition of convolution we get:\n","\n","$(f\\star k)_{o}(x)=\\frac{1}{N_i}\\sum_{i}^{N_i}\\sum_{j}^{F_{in}}\\frac{f_{ij}MLP_{jo}(x_i-x)}{p(x_i)}=$\n","\n","$=\\frac{1}{N_i}\\sum_{i}^{N_i}\\sum_{j}^{F_{in}}\\sum_{w}^{A}\\frac{f_{ij}H1_{w}(x_i-x)W_{wjo}}{p(x_i)}=$\n","\n","$=\\sum_{j}^{F_{in}}\\sum_{w}^{A} \\left( \\sum_{i}^{N_i}\\frac{f_{ij}H1_{w}(x_i-x)}{p(x_i)N_i}\\right) W_{wjo}$\n","\n","$a_{jw}=\\sum_{i}^{N_i}\\frac{f_{ij}H1_{w}(x_i-x)}{p(x_i)N_i}$\n","\n","$(f\\star k)_{o}(x)=\\sum_{j}^{F_{in}}\\sum_{w}^{A} a_{jw} W_{wjo}$\n","\n","Now we can compute $a_{jw}$ independently of the output feature and then use a simple matrix multiplication to compute the final convoluted output features.\n","\n","In this part of the exercise you will have to implement a spatial convolution operation using the low level API of tensorflow 2.0. You will need to look at functions such as: tf.gather_nd, tf.reshape, tf.reduce_sum, ...\n"]},{"cell_type":"code","metadata":{"id":"EwIhkSCf6yb-","colab_type":"code","colab":{}},"source":["def mc_conv(p_in_pts, \n","            p_in_pdf, \n","            p_in_neighbors, \n","            p_in_features, \n","            p_num_in_features, \n","            p_num_out_features):\n","  \"\"\" Method to create a monte carlo convolution layer.\n","  \n","  Params:\n","    p_in_pts (BxNx3): Tensor with the points for each model in the batch.\n","    p_in_pdf (BxN): Tensor with the pdf values for each point.\n","    p_in_neighbors (BxNx16): Tensor with the indices of the closest neighbors\n","      for each point.\n","    p_in_features (BxNxF): Tensor with the input features.\n","    p_num_out_features (int): Number of output features.\n","  Return:\n","    Tensor with the new convolved features.\n","  \"\"\"\n","  # Num Axes\n","  num_axes = 32\n","\n","  # Prepare the indices of the neighboring points.\n","  batch_indices = tf.tile(tf.reshape(tf.range(tf.shape(p_in_pts)[0]), \n","        (-1, 1, 1, 1)), (1, 512, 16, 1))\n","  expanded_neighbors = tf.expand_dims(p_in_neighbors, 3)\n","  idx = tf.concat([batch_indices, expanded_neighbors], axis = 3)\n","  \n","  ################# TODO\n","  # Get the 3D coordinates of the neighboring points and compute the difference\n","  # with the central point.\n","  neigh_pt_diffs = ...\n","  \n","  # Get the features of the neighboring points.\n","  neigh_features = ...\n","  \n","  # Get the pdf values of the neighboring points.\n","  neigh_pdfs = ...\n","  \n","  # Compute the projection of each neighbor into the axes (H1).\n","  h1 = ...\n","  \n","  # Compute the weighted input features for each axis (a_jw).\n","  a_jw = ...\n","  \n","  # Compute the final output features.\n","  out_features = ...\n","  ################# END TODO\n","  \n","  return out_features"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OALDYry0Inmq","colab_type":"text"},"source":["At this point we should have the function to create a Monte Carlo convolution implemented. Now we can use this building block to create our architecture. We are going to implemented a simple architecture with 3 MC convolutions, each of them followed by a batch normalization and activation function. The first one will output 64 features, the second one 128, and the third one 256. Then, we will apply an MLP to the convoluted features obtained for each point to classify the point into the different classes. We also concatenate to the features a one hot vector with the class of the object to simplify the task."]},{"cell_type":"code","metadata":{"id":"q9YETLadz4vQ","colab_type":"code","colab":{}},"source":["#Define the inputs to keras\n","inputs = tf.keras.Input(shape=(512, 3), name='batch_point_cloud')\n","pdfs = tf.keras.Input(shape=(512), name='batch_pdfs')\n","neighs = tf.keras.Input(shape=(512, 16), name='batch_neighs', dtype=tf.int32)\n","cats = tf.keras.Input(shape=(512), name='batch_cats', dtype=tf.int32)\n","cats_one_hot = tf.one_hot(cats, 16)\n","initFeatures = tf.reshape(tf.ones_like(pdfs, dtype=tf.float32), [-1, 512, 1])\n","\n","################# TODO\n","# Create the first layer with 64 features.\n","x = ...\n","\n","# Create the second layer with 128 features.\n","x = ...\n","\n","# Create the first layer with 256 features.\n","x = ...\n","################# END TODO\n","\n","#Concatenate the one hot vector to the features.\n","x = tf.concat([x, cats_one_hot], axis=-1)\n","\n","#Define the MLP to classify the points.\n","x = tf.keras.layers.Dense(128)(x)\n","x = tf.keras.layers.BatchNormalization()(x)\n","x = tf.keras.layers.Activation('relu')(x)\n","x = tf.keras.layers.Dropout(0.5)(x)\n","\n","#Create the final linear + softmax layer.\n","outputs = tf.keras.layers.Dense(50, activation='softmax')(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6J1lpJwJqWd","colab_type":"code","colab":{}},"source":["#Create the model.\n","model = tf.keras.Model(inputs=[inputs, pdfs, neighs, cats], outputs=outputs, \n","                       name='shapenet_model')\n","\n","#Compile the model.\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=tf.keras.optimizers.SGD(\n","                  learning_rate=0.0025, \n","                  momentum=0.98),\n","              metrics=['accuracy'])\n","\n","#Fit the model to the data.\n","model.fit([x_train, pdf_train, n_train, cat_train], y_train,\n","          batch_size=32,\n","          epochs=20,\n","          validation_data=([x_val, pdf_val, n_val, cat_val], y_val))\n","\n","#Evaluate the model on the test data.\n","model.evaluate([x_test, pdf_test, n_test, cat_test], y_test, verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XabzxNfO_1Yn","colab_type":"text"},"source":["# Resnet architecture\n"]},{"cell_type":"markdown","metadata":{"id":"jmzfxssp4iu8","colab_type":"text"},"source":["Now you can try variations on the architecture and learning rate to try to climb in the leaderboard. In this part of the exercise we are going to create the code to use resnet bottleneck blocks.\n","\n","This blocks are composed of a 1x1 convolution that reduces the number of features to a fourth of the input, then applies a spatial convolution, and finally another 1x1 convolution is applied to the features to increase the resolution to the same shape as the input. Then, the input and the output are added together to generate the final output of the layer."]},{"cell_type":"code","metadata":{"id":"MaB8s7LA8Hl0","colab_type":"code","colab":{}},"source":["def resnet_bottleneck_mc_conv(\n","            p_in_pts, \n","            p_in_pdf, \n","            p_in_neighbors, \n","            p_in_features, \n","            p_num_in_features):\n","  \"\"\" Method to create a resnet bottleneck block.\n","  \n","  Params:\n","    p_in_pts (BxNx3): Tensor with the points for each model in the batch.\n","    p_in_pdf (BxN): Tensor with the pdf values for each point.\n","    p_in_neighbors (BxNx16): Tensor with the indices of the closest neighbors\n","      for each point.\n","    p_in_features (BxNxF): Tensor with the input features.\n","    p_num_in_features (int): Number of input features.\n","  Return:\n","    Tensor with the new convolved features.\n","  \"\"\"\n","  # Batch norm the input\n","  batch_norm_in = tf.keras.layers.BatchNormalization()(p_in_features)\n","\n","  ################# TODO\n","  # Create the first 1x1 convolution to reduce the input size \n","  # to p_num_in_features//4\n","  x = ...\n","  \n","  # Create the spatial convolution\n","  x = ...\n","\n","  # Create the last 1x1 convolution to increase the input size \n","  # to p_num_in_features\n","  x = ...\n","  ################# END TODO\n","\n","  x = tf.keras.layers.BatchNormalization()(x)\n","\n","  # Return the addition of the input and output.\n","  return batch_norm_in + x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aqsvKIye8IFM","colab_type":"text"},"source":["Now we are going to use this blocks to create a new network architecture. First, we will create a monte carlo convolution to create the initial features (64), then we will apply a resnet block. After, we will apply a 1x1 convolution to increase the number of features to 128 and then another resnet block. Lastly, we will use a 1x1 convolution to increase the resolution to 256 features and we will apply the last resnet block.\n"]},{"cell_type":"code","metadata":{"id":"cFbdHQsy8EpD","colab_type":"code","colab":{}},"source":["#Define the inputs to keras\n","inputs = tf.keras.Input(shape=(512, 3), name='batch_point_cloud')\n","pdfs = tf.keras.Input(shape=(512), name='batch_pdfs')\n","neighs = tf.keras.Input(shape=(512, 16), name='batch_neighs', dtype=tf.int32)\n","cats = tf.keras.Input(shape=(512), name='batch_cats', dtype=tf.int32)\n","cats_one_hot = tf.one_hot(cats, 16)\n","initFeatures = tf.reshape(tf.ones_like(pdfs, dtype=tf.float32), [-1, 512, 1])\n","\n","################# TODO\n","# Create the first spatial convolution with 64 output features.\n","x = ...\n","\n","# Create the first resnet block.\n","x = ...\n","\n","# Create the 1x1 convolution to increase the number of features to 128.\n","x = ...\n","\n","# Create the second resnet block.\n","x = ...\n","\n","# Create the 1x1 convolution to increase the number of features to 256.\n","x = ...\n","\n","# Create the third resnet block.\n","x = ...\n","\n","################# END TODO\n","\n","#Concatenate the one hot vector to the features.\n","x = tf.concat([x, cats_one_hot], axis=-1)\n","\n","#Define the MLP to classify the points.\n","x = tf.keras.layers.Dense(128)(x)\n","x = tf.keras.layers.BatchNormalization()(x)\n","x = tf.keras.layers.Activation('relu')(x)\n","x = tf.keras.layers.Dropout(0.5)(x)\n","\n","#Create the final linear + softmax layer.\n","outputs = tf.keras.layers.Dense(50, activation='softmax')(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2S0VcB1r-RLy","colab_type":"code","colab":{}},"source":["#Create the model.\n","model = tf.keras.Model(inputs=[inputs, pdfs, neighs, cats], outputs=outputs, \n","                       name='shapenet_model')\n","\n","#Compile the model.\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=tf.keras.optimizers.SGD(\n","                  learning_rate=0.0025, \n","                  momentum=0.98),\n","              metrics=['accuracy'])\n","\n","#Fit the model to the data.\n","model.fit([x_train, pdf_train, n_train, cat_train], y_train,\n","          batch_size=32,\n","          epochs=20,\n","          validation_data=([x_val, pdf_val, n_val, cat_val], y_val))\n","\n","#Evaluate the model on the test data.\n","model.evaluate([x_test, pdf_test, n_test, cat_test], y_test, verbose=0)"],"execution_count":0,"outputs":[]}]}